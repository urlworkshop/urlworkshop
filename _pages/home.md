---
layout: project
urltitle:  "Unsupervised Reinforcement Learning (URL)"
title: "Unsupervised Reinforcement Learning (URL)"
categories: workshop, icml, unsupervised learning, self-supervised learning, reinforcement learning, deep learning, 2021
permalink: /
bibtex: true
paper: true
acknowledgements: ""
---
<div class="alert" role="alert">



</div>
<div class="row reverse">
    <h1>Unsupervised Reinforcement Learning @ ICML 2021</h1>
    <br>
      <br>
    <img class="cover" src="/static/img/cover.jpeg">
    <br>
      <br>


</div>

<div class="row" id="abstract">


    <p>
        Unsupervised learning (UL) has begun to deliver on its promise in the recent past with tremendous progress made in the fields of natural language processing and computer vision whereby large scale unsupervised pre-training has enabled fine-tuning to downstream supervised learning tasks with limited labeled data. This is particularly encouraging and appealing in the context of reinforcement learning considering that it is expensive to perform rollouts in the real world with annotations either in the form of reward signals or human demonstrations. We therefore believe that a workshop in the intersection of unsupervised and reinforcement learning (RL) is timely and we hope to bring together researchers with diverse views on how to make further progress in this exciting and open-ended subfield.

    </p>
</div>


<br />

<hr />

<div class="row" id="dates">

    <h2>Important Dates</h2>

</div>


<div class="row">
    <table class="table table-striped">
      <tbody>
        <tr>
          <td>Paper Submission Deadline</td>
          <td>June 9, 2021 AoE</td>
        </tr>
        <tr>
          <td>Decision Notifications</td>
          <td>June 30, 2021</td>
        </tr>
        <tr>
          <td>Camera Ready Paper Deadline</td>
          <td>July 17, 2021 AoE</td>
        </tr>
        <tr>
          <td>Workshop</td>
          <td>July 24, 2021</td>
        </tr>
      </tbody>
    </table>
</div>

<br />
<hr />
<div class="row" id="cfp">

    <h2>Call for Papers</h2>

</div>






<div class="row">
    <p>
      We invite both short (4 page) and long (8 page) anonymized submissions in the <a href="https://media.icml.cc/Conferences/ICML2021/Styles/icml2021_style.zip">ICML LaTeX format</a> that
      study questions regarding the best ways of combining unsupervised learning with RL. More concretely, we welcome submissions around, but not necessarily limited to, the following broad questions:
    </p>
    <p>
          <ul>
              <li>How can the use of UL advance RL?</li>
              <li>What are the most effective ways of combining UL with RL?</li>
              <li>What are the settings in which UL can be most beneficial in RL?</li>
              <li>How is Representation Learning for RL different from downstream supervised tasks?</li>
              <li>How can UL improve RL in terms of sample efficiency, generalization, exploration?</li>
              <li>How can UL and Skill Discovery be maximally synergetic?</li>
              <li>How does the role of UL differ across Model-based RL, Model-free On-policy RL, Model-free Off-policy RL, Offline RL?</li>
              <li>What inspirations can we take from cognitive science to bridge to inspire the next crop of UL methods for RL?</li>
              <li>Is there a unified view to combine different UL methods into a single framework?</li>
          </ul>
      </p>
      <p>This workshop will bring together researchers working in unsupervised learning (including those in computer vision or natural language processing), representation learning and reinforcement learning to discuss the benefits, challenges and potential solutions for effectively using unsupervised learning techniques to enhance reinforcement learning agents. Early workshops were crucial to accelerate the use of UL techniques in vision and language, and we hope this workshop will serve as the kindling for UL techniques in RL.</p>
      <p>
       Note that as per ICML guidelines, we don't accept works previously published in other conferences on machine learning, but are open to works that are currently under submission to a conference (such as NeurIPS 2021).</p>

      <p>
        Submissions should be uploaded on OpenReview: <a class="red" href="https://openreview.net/group?id=ICML.cc/2021/Workshop/URL">URL submission link</a>
      </p>
      <p>
        In case of any issues or questions, feel free to email the workshop organizers at: <a href="mailto:url.icml2021@gmail.com" class="red">url.icml2021@gmail.com</a>.
      </p>

</div>


<br />


<hr />

<div class="row" id="speakers">
    <h2>Speakers</h2>
</div>

<div class="row">
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://ai.stanford.edu/~cbfinn/">
      <img class="people-pic" src="{{ "/static/img/people/chelsea_finn.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://ai.stanford.edu/~cbfinn/">Chelsea Finn</a>
      <h6>Stanford</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://web.mit.edu/krallen/www/">
      <img class="people-pic" src="{{ "/static/img/people/kelsey_allen.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://web.mit.edu/krallen/www/">Kelsey Allen</a>
      <h6>DeepMind</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://danijar.com/">
      <img class="people-pic" src="{{ "/static/img/people/danijar_hafner.jpg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://danijar.com/">Danijar Hafner</a>
      <h6>University of Toronto</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://nke001.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/nan_rosemary_ke.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://nke001.github.io/">Nan Rosemary Ke</a>
      <h6>MILA</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="http://chercheurs.lille.inria.fr/~lazaric/Webpage/Home/Home.html">
      <img class="people-pic" src="{{ "/static/img/people/alessandro_lazaric.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://chercheurs.lille.inria.fr/~lazaric/Webpage/Home/Home.html">Alessandro Lazaric</a>
      <h6>Facebook AI Research</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="http://www.cs.umd.edu/~kdbrant/">
      <img class="people-pic" src="{{ "/static/img/people/kiante_brantley.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://www.cs.umd.edu/~kdbrant/">Kiante Brantley</a>
      <h6>Maryland College Park</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://research.google/people/105004/">
      <img class="people-pic" src="{{ "/static/img/people/david_ha.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://research.google/people/105004/">David Ha</a>
      <h6>Google Brain</h6>
    </div>
  </div>
</div>

<hr />

<div class="row" id="intro">
        <h2>Introduction</h2>
        <p>For decades unsupervised learning (UL) has promised to drastically reduce our reliance on supervision and reinforcement. Now, in the last couple of years, unsupervised learning has been delivering on this problem with substantial advances in computer vision (e.g., CPC [1], SimCLR [2], MoCo [3], BYOL [4]) and natural language processing (e.g., BERT [5], GPT-3 [6], T5 [7], Roberta [8]). The general purpose representations learned by unsupervised methods are useful for a variety of downstream supervised learning tasks, particularly in the low data regime (BERT [5], GPT-3 [6], T5 [7], CPCv2 [9], SimCLR [2], SimCLRv2 [10]).</p>
  <p>
  However, in the context of reinforcement learning, we havenâ€™t seen the level of impact UL has had in vision and language. This is not for the lack of trying. There has been a wide variety of methods developed by the Machine Learning community to use UL to make a meaningful impact in RL. A few prominent directions are as follows:</p>
  <p>
  <ul>

  <li>Learning rich representations of high dimensional observations to aid reinforcement learning (UNREAL [11], DARLA [12], TCN [13], SAC-AE [14], SLAC [15], CURL [16], DrQ [17], RAD [18], ATC [19], Bisimulation [20], Proto-RL [21]).</li>
  <li>Building world models for planning (Visual MPC [22], Simple [23], PlaNet [24], Dreamer [25], MuZero [26]).</li>
  <li>Learning to explore environments with sparse reward signals (EX2 [27], Curiosity [28], RND [29]).</li>
  <li>Learning task agnostic, diverse and reusable skills (VIC [30], VALOR [31], DIAYN [32],, DADS [33]).</li>
  <li>Extracting signals for free with goal-conditioned and hindsight models (UVFA [34], HER [35], Asymmetric Self-Play [36], RIG [37], Learning From Play [38]).</li>
  <li>Unsupervised Learning in the context of Meta/Multi-Task Learning (CARML [39], UML [40]).</li>

  </ul>
  </p>

</div>




<hr />

<div class="row" id="organizers">
    <h2>Organizers</h2>
</div>
<div class="row">
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://feryal.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/feryal_behbahani.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://feryal.github.io/">Feryal Behbahani</a>
      <h6>DeepMind</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://www.cs.mcgill.ca/~jpineau/">
      <img class="people-pic" src="{{ "/static/img/people/joelle_pineau.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.cs.mcgill.ca/~jpineau/">Joelle Pineau</a>
      <h6>McGill University / Mila / FAIR</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://www.lerrelpinto.com/">
      <img class="people-pic" src="{{ "/static/img/people/lerrel_pinto.jpeg" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://www.lerrelpinto.com/">Lerrel Pinto</a>
      <h6>NYU</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://rraileanu.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/roberta_raileanu.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name people">
      <a href="https://rraileanu.github.io/">Roberta Raileanu</a>
      <h6>NYU</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://amyzhang.github.io/">
      <img class="people-pic" src="{{ "/static/img/people/amy_zhang.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://amyzhang.github.io/">Amy Zhang</a>
      <h6>McGill University / Mila / FAIR</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="https://people.eecs.berkeley.edu/~aravind/">
      <img class="people-pic" src="{{ "/static/img/people/aravind_srinivas.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="https://people.eecs.berkeley.edu/~aravind/">Aravind Srinivas</a>
      <h6>UC Berkeley</h6>
    </div>
  </div>
  <div class="col-xs-6 col-lg-3 people">
    <a href="http://denis-yarats.info/">
      <img class="people-pic" src="{{ "/static/img/people/denis_yarats.png" | prepend:site.baseurl }}">
    </a>
    <div class="people-name">
      <a href="http://denis-yarats.info/">Denis Yarats</a>
      <h6>NYU / FAIR</h6>
    </div>
  </div>
</div>

<hr />

<div class="row">
    <h2>References</h2>
</div>




<div class="row">
<ol>
  <li>Oord et al. "Representation Learning with Contrastive Predictive Coding." arXiv (2018).</li>
  <li>Chen et al. "A Simple Framework for Contrastive Learning of Visual Representations." ICML (2020).</li>
  <li> He et al. "Momentum Contrast for Unsupervised Visual Representation Learning." CVPR (2020).</li>
  <li>Grill et al. "Bootstrap your own latent: A new approach to self-supervised Learning". NeurIPS (2020).</li>
  <li>Devlin et al. "BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding." NAACL 2019.</li>
  <li>OpenAI "Language Models are Few-Shot Learners." ArXiv (2020).</li>
  <li>Raffel et al. "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer."  ArXiv (2019).</li>
  <li>Lie et al. "RoBERTa: A Robustly Optimized BERT Pretraining Approach." ArXiv (2019).</li>
  <li>HÃ©naff et al. "Data-Efficient Image Recognition with Contrastive Predictive Coding." ArXiv (2019).</li>
  <li>Chen et al. "Big Self-Supervised Models are Strong Semi-Supervised Learners." NeurIPS (2020).</li>
  <li>Jaderberg et al. "Reinforcement Learning with Unsupervised Auxiliary Tasks." ICLR 2017.</li>
  <li>Higgins et al. "DARLA: Improving Zero-Shot Transfer in Reinforcement Learning." ICML 2017.</li>
  <li>Sermanet et al. "Time-Contrastive Networks: Self-Supervised Learning from Video." ArXiv 2017.</li>
  <li>Yarats et al. "Improving Sample Efficiency in Model-Free Reinforcement Learning from Images." AAAI (2021).</li>
  <li>Lee et al. "Stochastic Latent Actor-Critic: Deep Reinforcement Learning with a Latent Variable Model." ArXiv (2019).</li>
  <li>Srinivas et al. "Contrastive Unsupervised Representations for Reinforcement Learning." ICML (2020).</li>
  <li>Yarats et al. "Image Augmentation Is All You Need: Regularizing Deep Reinforcement Learning from Pixels." ICLR (2021).</li>
  <li>Laskin et al. "Reinforcement Learning with Augmented Data." NeurIPS (2020).</li>
  <li>Stook et al. "Decoupling Representation Learning from Reinforcement Learning." ArXiv (2020).</li>
  <li>Zhang et al. "Learning Invariant Representations for Reinforcement Learning without Reconstruction." ICLR (2021).</li>
  <li>Yarats et al. "Reinforcement Learning with Prototypical Representations." ArXiv (2021).</li>
  <li>Hirose et al. "Deep Visual MPC-Policy Learning for Navigation." ArXiv (2019).</li>
  <li>Kaiser et al. "Model-Based Reinforcement Learning for Atari." ArXiv (2019).</li>
  <li>Hafner et al. "Learning Latent Dynamics for Planning from Pixels." ICML (2019).</li>
  <li>Hafner et al. "Dream to Control: Learning Behaviors by Latent Imagination." ICLR (2020).</li>
  <li>Schrittwieser et al. "Mastering Atari, Go, chess and shogi by planning with a learned model." Nature (2020).</li>
  <li>Fu et al. "EX2: Exploration with Exemplar Models for Deep Reinforcement Learning." ArXiv (2017).</li>
  <li>Pathak et al. "Curiosity-driven Exploration by Self-supervised Prediction." ICML (2017).</li>
  <li>Burda et al. "Exploration by random network distillation." ICLR (2019).</li>
  <li>Gregor et al. "Variational Intrinsic Control." ArXiv (2016). </li>
  <li>Achiam et al. "Variational Option Discovery Algorithms." ArXiv (2018).</li>
  <li>Eysenbach et al. "Diversity is All You Need: Learning Skills without a Reward Function." ICLR (2019).</li>
  <li>Sharma et al. "Dynamics-Aware Unsupervised Discovery of Skills." ICLR (2020).</li>
  <li>Schaul et al. "Universal Value Function Approximators." ICML (2015).</li>
  <li>Andrychowicz et al. "Hindsight Experience Replay." NeurIPS (2017).</li>
  <li>Sukhbaatar et al. "Intrinsic Motivation and Automatic Curricula via Asymmetric Self-Play." ICLR (2018).</li>
  <li>Nair et al. "Visual Reinforcement Learning with Imagined Goals." NeurIPS (2018).</li>
  <li>Lynch et al. "Learning Latent Plans from Play." CoRL (2019).</li>
  <li>Jabri et al. "Unsupervised Curricula for Visual Meta-Reinforcement Learning." NeurIPS (2019).</li>
  <li>Gupta et al. "Unsupervised Meta-Learning for Reinforcement Learning." ICLR (2019).</li>

</ol>

</div>

<div class="text-center p-3" style="background-color: rgba(0, 0, 0, 0)">
    <h6>Website theme inspired from the <a href="https://github.com/vigilworkshop/vigilworkshop.github.io">VIGIL workshop</a>. Cover art by <a href="https://www.mattdixon.co.uk">Matt Dixon</a></h6>
  </div>
